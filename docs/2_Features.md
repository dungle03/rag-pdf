# âœ¨ TÃ­nh nÄƒng vÃ  Cáº¥u hÃ¬nh Chi tiáº¿t

TÃ i liá»‡u nÃ y mÃ´ táº£ chi tiáº¿t cÃ¡c tÃ­nh nÄƒng cá»‘t lÃµi cá»§a RAG PDF QA System, bao gá»“m nguyÃªn lÃ½ hoáº¡t Ä‘á»™ng, use cases thá»±c táº¿, vÃ  hÆ°á»›ng dáº«n tinh chá»‰nh tham sá»‘ Ä‘á»ƒ tá»‘i Æ°u cho tá»«ng trÆ°á»ng há»£p sá»­ dá»¥ng cá»¥ thá»ƒ.

---

## ğŸ” Há»‡ thá»‘ng TÃ¬m kiáº¿m Lai (Hybrid Search)

### Tá»•ng quan

Hybrid Search káº¿t há»£p **hai phÆ°Æ¡ng phÃ¡p bá»• trá»£** Ä‘á»ƒ tÃ¬m kiáº¿m thÃ´ng tin chÃ­nh xÃ¡c hÆ¡n:
- **Vector Search (Dense Retrieval)**: TÃ¬m kiáº¿m theo **ngá»¯ nghÄ©a**, hiá»ƒu Ä‘Æ°á»£c Ã½ nghÄ©a cÃ¢u há»i ngay cáº£ khi khÃ´ng cÃ³ tá»« khÃ³a chÃ­nh xÃ¡c.
- **Keyword Search (Sparse Retrieval)**: TÃ¬m kiáº¿m theo **tá»« khÃ³a**, Ä‘áº£m báº£o cÃ¡c thuáº­t ngá»¯ quan trá»ng Ä‘Æ°á»£c khá»›p chÃ­nh xÃ¡c.

### CÃ¡ch hoáº¡t Ä‘á»™ng chi tiáº¿t

#### 1. Dense Retrieval (Vector Search)
**NguyÃªn lÃ½:**
- Má»—i chunk text vÃ  cÃ¢u há»i Ä‘Æ°á»£c chuyá»ƒn thÃ nh vector 768 chiá»u báº±ng `Gemini text-embedding-004`.
- TÃ­nh Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng cosine giá»¯a vector cÃ¢u há»i vÃ  cÃ¡c vector chunks.
- Káº¿t quáº£: TÃ¬m Ä‘Æ°á»£c cÃ¡c chunks cÃ³ **ngá»¯ nghÄ©a gáº§n** vá»›i cÃ¢u há»i.

**VÃ­ dá»¥ thá»±c táº¿:**
```
CÃ¢u há»i: "Nghá»‰ phÃ©p Ä‘Æ°á»£c bao nhiÃªu ngÃ y?"
Chunk tÃ¬m Ä‘Æ°á»£c: "NhÃ¢n viÃªn Ä‘Æ°á»£c hÆ°á»Ÿng 12 ngÃ y nghá»‰ cÃ³ lÆ°Æ¡ng hÃ ng nÄƒm."
â†’ KhÃ´ng cÃ³ tá»« "bao nhiÃªu" nhÆ°ng váº«n tÃ¬m Ä‘Æ°á»£c vÃ¬ ngá»¯ nghÄ©a phÃ¹ há»£p.
```

**Æ¯u Ä‘iá»ƒm:**
- Hiá»ƒu Ä‘Æ°á»£c cÃ¢u há»i Ä‘áº·t theo nhiá»u cÃ¡ch khÃ¡c nhau
- TÃ¬m Ä‘Æ°á»£c thÃ´ng tin liÃªn quan ngay cáº£ khi dÃ¹ng tá»« Ä‘á»“ng nghÄ©a
- Xá»­ lÃ½ tá»‘t cÃ¢u há»i tiáº¿ng Viá»‡t tá»± nhiÃªn

**NhÆ°á»£c Ä‘iá»ƒm:**
- CÃ³ thá»ƒ bá» sÃ³t thÃ´ng tin náº¿u thuáº­t ngá»¯ chuyÃªn ngÃ nh quan trá»ng khÃ´ng náº±m trong ngá»¯ cáº£nh training

#### 2. Sparse Retrieval (BM25 Keyword Search)
**NguyÃªn lÃ½:**
- Sá»­ dá»¥ng thuáº­t toÃ¡n **BM25** (Best Matching 25) - cáº£i tiáº¿n cá»§a TF-IDF.
- ÄÃ¡nh giÃ¡ táº§n suáº¥t xuáº¥t hiá»‡n cá»§a tá»« khÃ³a trong chunk vÃ  Ä‘á»™ hiáº¿m cá»§a tá»« trong toÃ n bá»™ tÃ i liá»‡u.
- Káº¿t quáº£: TÃ¬m Ä‘Æ°á»£c cÃ¡c chunks cÃ³ **tá»« khÃ³a khá»›p chÃ­nh xÃ¡c**.

**CÃ´ng thá»©c BM25 (Ä‘Æ¡n giáº£n hÃ³a):**
```
score(chunk, query) = Î£ IDF(term) Ã— (TF(term) Ã— (k+1)) / (TF(term) + k)
```
- `TF`: Term Frequency - táº§n suáº¥t tá»« trong chunk
- `IDF`: Inverse Document Frequency - Ä‘á»™ hiáº¿m cá»§a tá»«
- `k`: Tham sá»‘ Ä‘iá»u chá»‰nh (thÆ°á»ng = 1.5)

**VÃ­ dá»¥ thá»±c táº¿:**
```
CÃ¢u há»i: "Quy Ä‘á»‹nh vá» ISO 9001 trong cÃ´ng ty?"
Chunk tÃ¬m Ä‘Æ°á»£c: "CÃ´ng ty Ä‘Ã£ Ä‘áº¡t chá»©ng nháº­n ISO 9001:2015 vÃ o nÄƒm 2023."
â†’ TÃ¬m Ä‘Æ°á»£c vÃ¬ khá»›p chÃ­nh xÃ¡c tá»« "ISO 9001"
```

**Æ¯u Ä‘iá»ƒm:**
- TÃ¬m chÃ­nh xÃ¡c cÃ¡c thuáº­t ngá»¯ ká»¹ thuáº­t, mÃ£ sá»‘, tÃªn riÃªng
- KhÃ´ng cáº§n API embedding, xá»­ lÃ½ nhanh
- Hoáº¡t Ä‘á»™ng tá»‘t vá»›i tá»« khÃ³a tiáº¿ng Anh trong vÄƒn báº£n tiáº¿ng Viá»‡t

**NhÆ°á»£c Ä‘iá»ƒm:**
- KhÃ´ng hiá»ƒu ngá»¯ nghÄ©a, chá»‰ khá»›p tá»« Ä‘Ãºng chÃ­nh táº£
- KhÃ´ng tÃ¬m Ä‘Æ°á»£c thÃ´ng tin náº¿u cÃ¢u há»i dÃ¹ng tá»« Ä‘á»“ng nghÄ©a

#### 3. Hybrid Fusion - Káº¿t há»£p hai phÆ°Æ¡ng phÃ¡p
**CÃ´ng thá»©c káº¿t há»£p:**
```python
hybrid_score = (1 - alpha) Ã— vector_score + alpha Ã— bm25_score
```

**VÃ­ dá»¥ cá»¥ thá»ƒ vá»›i alpha = 0.6:**
```
Chunk A: 
  - Vector score = 0.85 (ngá»¯ nghÄ©a ráº¥t gáº§n)
  - BM25 score = 0.30 (Ã­t tá»« khÃ³a khá»›p)
  - Hybrid = 0.4 Ã— 0.85 + 0.6 Ã— 0.30 = 0.34 + 0.18 = 0.52

Chunk B:
  - Vector score = 0.60 (ngá»¯ nghÄ©a khÃ¡ gáº§n)
  - BM25 score = 0.90 (nhiá»u tá»« khÃ³a khá»›p chÃ­nh xÃ¡c)
  - Hybrid = 0.4 Ã— 0.60 + 0.6 Ã— 0.90 = 0.24 + 0.54 = 0.78
  
â†’ Chunk B Ä‘Æ°á»£c Æ°u tiÃªn vÃ¬ cÃ¢n báº±ng giá»¯a ngá»¯ nghÄ©a vÃ  tá»« khÃ³a
```

#### 4. MMR (Maximal Marginal Relevance) - Äa dáº¡ng hÃ³a káº¿t quáº£
**Má»¥c Ä‘Ã­ch:** TrÃ¡nh tráº£ vá» nhiá»u chunks cÃ³ ná»™i dung trÃ¹ng láº·p.

**CÃ´ng thá»©c MMR:**
```python
MMR = Î» Ã— similarity(chunk, query) - (1-Î») Ã— max_similarity(chunk, selected_chunks)
```

**VÃ­ dá»¥:**
```
Query: "ChÃ­nh sÃ¡ch lÃ m viá»‡c tá»« xa"

KhÃ´ng cÃ³ MMR (Î» = 1.0):
  1. "ChÃ­nh sÃ¡ch WFH: NhÃ¢n viÃªn Ä‘Æ°á»£c lÃ m viá»‡c tá»« xa 2 ngÃ y/tuáº§n"
  2. "WFH policy: Employees work from home 2 days per week" (báº£n tiáº¿ng Anh)
  3. "LÃ m viá»‡c tá»« xa: Tá»‘i Ä‘a 2 ngÃ y má»—i tuáº§n"
  â†’ Ba chunks gáº§n nhÆ° giá»‘ng nhau!

CÃ³ MMR (Î» = 0.7):
  1. "ChÃ­nh sÃ¡ch WFH: NhÃ¢n viÃªn Ä‘Æ°á»£c lÃ m viá»‡c tá»« xa 2 ngÃ y/tuáº§n"
  2. "Thiáº¿t bá»‹ há»— trá»£ WFH: CÃ´ng ty cáº¥p laptop vÃ  mÃ n hÃ¬nh"
  3. "Quy trÃ¬nh Ä‘Äƒng kÃ½ WFH qua há»‡ thá»‘ng ná»™i bá»™"
  â†’ ThÃ´ng tin Ä‘a dáº¡ng hÆ¡n, bao quÃ¡t nhiá»u khÃ­a cáº¡nh!
```

**Khuyáº¿n nghá»‹ `MMR_LAMBDA`:**
- `0.9-1.0`: Æ¯u tiÃªn relevance tuyá»‡t Ä‘á»‘i (Ã­t Ä‘a dáº¡ng)
- `0.7` (default): CÃ¢n báº±ng giá»¯a relevance vÃ  Ä‘a dáº¡ng
- `0.3-0.5`: Ráº¥t Ä‘a dáº¡ng (cÃ³ thá»ƒ giáº£m Ä‘á»™ chÃ­nh xÃ¡c)

#### 5. Cross-Encoder Reranking
**NguyÃªn lÃ½:**
- Sau khi cÃ³ top-K candidates tá»« hybrid search, dÃ¹ng model `BGE reranker-base` Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ láº¡i.
- Cross-encoder xem xÃ©t **cáº£ cÃ¢u há»i vÃ  chunk cÃ¹ng lÃºc**, cho Ä‘iá»ƒm chÃ­nh xÃ¡c hÆ¡n bi-encoder (vector search).

**So sÃ¡nh Bi-encoder vs Cross-encoder:**
```
Bi-encoder (Vector Search):
  embed(query) â†’ [v1]
  embed(chunk) â†’ [v2]
  score = cosine(v1, v2)
  â†’ Nhanh nhÆ°ng khÃ´ng xem xÃ©t tÆ°Æ¡ng tÃ¡c giá»¯a query vÃ  chunk

Cross-encoder (Reranker):
  model([query, chunk]) â†’ score
  â†’ Cháº­m hÆ¡n nhÆ°ng chÃ­nh xÃ¡c hÆ¡n vÃ¬ xem xÃ©t toÃ n bá»™ ngá»¯ cáº£nh
```

**Trade-off:**
- **Báº­t reranker** (`RERANK_ON=true`): TÄƒng accuracy 5-15%, tÄƒng latency ~500ms
- **Táº¯t reranker** (`RERANK_ON=false`): Pháº£n há»“i nhanh hÆ¡n, accuracy giáº£m nháº¹

### Báº£ng cáº¥u hÃ¬nh Hybrid Search

| Biáº¿n | MÃ´ táº£ chi tiáº¿t | GiÃ¡ trá»‹ máº·c Ä‘á»‹nh | Khuyáº¿n nghá»‹ |
|---|---|---|---|
| `HYBRID_ON` | Báº­t/táº¯t Hybrid Search.<br/>â€¢ `true`: Káº¿t há»£p Vector + BM25<br/>â€¢ `false`: Chá»‰ dÃ¹ng Vector Search | `true` | LuÃ´n báº­t cho Ä‘á»™ chÃ­nh xÃ¡c cao nháº¥t |
| `HYBRID_ALPHA` | Trá»ng sá»‘ BM25 trong cÃ´ng thá»©c hybrid.<br/>â€¢ `0.0`: Chá»‰ dÃ¹ng Vector Search<br/>â€¢ `0.5`: CÃ¢n báº±ng 50-50<br/>â€¢ `1.0`: Chá»‰ dÃ¹ng BM25 | `0.6` | â€¢ `0.6-0.7` cho vÄƒn báº£n ká»¹ thuáº­t (nhiá»u thuáº­t ngá»¯)<br/>â€¢ `0.3-0.4` cho vÄƒn báº£n tá»± nhiÃªn |
| `RETRIEVE_TOP_K` | Sá»‘ chunks ban Ä‘áº§u láº¥y tá»« hybrid search.<br/>Sá»‘ nÃ y pháº£i **lá»›n hÆ¡n** `CONTEXT_K` Ä‘á»ƒ cÃ³ khÃ´ng gian cho MMR vÃ  reranking. | `12` | â€¢ `10-15` cho dataset nhá» (<100 pages)<br/>â€¢ `20-30` cho dataset lá»›n (>500 pages) |
| `CONTEXT_K` | Sá»‘ chunks cuá»‘i cÃ¹ng gá»­i Ä‘áº¿n LLM.<br/>Quyáº¿t Ä‘á»‹nh **Ä‘á»™ dÃ i context window**. | `10` | â€¢ `6-8` cho cÃ¢u há»i Ä‘Æ¡n giáº£n<br/>â€¢ `10-12` cho cÃ¢u há»i phá»©c táº¡p cáº§n nhiá»u ngá»¯ cáº£nh |
| `MMR_LAMBDA` | Há»‡ sá»‘ Ä‘a dáº¡ng hÃ³a.<br/>â€¢ `1.0`: KhÃ´ng Ä‘a dáº¡ng, chá»‰ relevance<br/>â€¢ `0.5`: CÃ¢n báº±ng<br/>â€¢ `0.0`: Äa dáº¡ng tá»‘i Ä‘a (cÃ³ thá»ƒ máº¥t relevance) | `0.7` | â€¢ `0.8-0.9` cho cÃ¢u há»i cáº§n Ä‘á»™ chÃ­nh xÃ¡c cao<br/>â€¢ `0.5-0.6` cho cÃ¢u há»i khÃ¡m phÃ¡ |
| `RERANK_ON` | Báº­t/táº¯t Cross-encoder Reranking.<br/>**Trade-off:** Accuracy +10% nhÆ°ng latency +500ms | `true` | â€¢ `true` cho production (Ä‘á»™ chÃ­nh xÃ¡c quan trá»ng)<br/>â€¢ `false` cho development (tá»‘c Ä‘á»™ Æ°u tiÃªn) |

### Use Cases vÃ  Tuning Tips

#### Use Case 1: TÃ i liá»‡u ká»¹ thuáº­t vá»›i nhiá»u thuáº­t ngá»¯
**Äáº·c Ä‘iá»ƒm:** Chá»©a mÃ£ sá»‘, thuáº­t ngá»¯ tiáº¿ng Anh, kÃ½ hiá»‡u ká»¹ thuáº­t.

**Cáº¥u hÃ¬nh khuyáº¿n nghá»‹:**
```ini
HYBRID_ON=true
HYBRID_ALPHA=0.7          # Æ¯u tiÃªn BM25 Ä‘á»ƒ khá»›p thuáº­t ngá»¯ chÃ­nh xÃ¡c
RETRIEVE_TOP_K=15
CONTEXT_K=8
MMR_LAMBDA=0.8            # Ãt Ä‘a dáº¡ng, Æ°u tiÃªn relevance cao
RERANK_ON=true
```

**VÃ­ dá»¥:** TÃ i liá»‡u vá» API, database schema, quy chuáº©n ISO.

#### Use Case 2: VÄƒn báº£n tá»± nhiÃªn, cÃ¢u há»i má»Ÿ
**Äáº·c Ä‘iá»ƒm:** NgÃ´n ngá»¯ tá»± nhiÃªn, Ã­t thuáº­t ngá»¯, cáº§n hiá»ƒu ngá»¯ cáº£nh.

**Cáº¥u hÃ¬nh khuyáº¿n nghá»‹:**
```ini
HYBRID_ON=true
HYBRID_ALPHA=0.4          # Æ¯u tiÃªn Vector Search Ä‘á»ƒ hiá»ƒu ngá»¯ nghÄ©a
RETRIEVE_TOP_K=12
CONTEXT_K=10              # Cáº§n nhiá»u context Ä‘á»ƒ hiá»ƒu toÃ n cáº£nh
MMR_LAMBDA=0.6            # Äa dáº¡ng vá»«a pháº£i
RERANK_ON=true
```

**VÃ­ dá»¥:** SÃ¡ch giÃ¡o khoa, tÃ i liá»‡u Ä‘Ã o táº¡o, policy vÄƒn báº£n.

#### Use Case 3: Dataset nhá», cáº§n pháº£n há»“i nhanh
**Äáº·c Ä‘iá»ƒm:** <50 pages, Ã­t chunks, cáº§n tá»‘c Ä‘á»™.

**Cáº¥u hÃ¬nh khuyáº¿n nghá»‹:**
```ini
HYBRID_ON=true
HYBRID_ALPHA=0.5
RETRIEVE_TOP_K=8          # Ãt candidates vÃ¬ dataset nhá»
CONTEXT_K=5
MMR_LAMBDA=0.7
RERANK_ON=false           # Táº¯t Ä‘á»ƒ giáº£m latency
```

---

## ğŸ†• TÃ­nh nÄƒng Recency Boost - Æ¯u tiÃªn ThÃ´ng tin Má»›i

### Tá»•ng quan

**Recency Boost** tá»± Ä‘á»™ng phÃ¡t hiá»‡n vÃ  Æ°u tiÃªn chunks tá»« tÃ i liá»‡u má»›i hÆ¡n khi ranking káº¿t quáº£. TÃ­nh nÄƒng nÃ y cá»±c ká»³ há»¯u Ã­ch khi:
- CÃ³ nhiá»u phiÃªn báº£n cá»§a cÃ¹ng má»™t tÃ i liá»‡u (policy v1, v2, v3...)
- ThÃ´ng tin Ä‘Æ°á»£c cáº­p nháº­t thÆ°á»ng xuyÃªn (news, blog, quy Ä‘á»‹nh)
- Cáº§n Ä‘áº£m báº£o cÃ¢u tráº£ lá»i luÃ´n dá»±a trÃªn thÃ´ng tin má»›i nháº¥t

### CÃ¡ch hoáº¡t Ä‘á»™ng chi tiáº¿t

#### BÆ°á»›c 1: Document Registration (ÄÄƒng kÃ½ tÃ i liá»‡u)
Khi upload má»™t file PDF má»›i:

```python
# 1. TÃ­nh SimHash fingerprint (128-bit)
fingerprint = compute_simhash(full_document_text)

# 2. So sÃ¡nh vá»›i cÃ¡c document Ä‘Ã£ cÃ³
for existing_doc in database:
    hamming_dist = count_different_bits(fingerprint, existing_doc.fingerprint)
    
    if hamming_dist < 20:  # Threshold = 20 bits
        # ÄÃ¢y lÃ  phiÃªn báº£n má»›i cá»§a document cÅ©!
        existing_doc.status = "superseded"  # ÄÃ¡nh dáº¥u cÅ©
        new_doc.status = "active"           # ÄÃ¡nh dáº¥u má»›i
        new_doc.version = existing_doc.version + 1
```

**VÃ­ dá»¥ thá»±c táº¿:**
```
NgÃ y 1/1/2024: Upload "hr_policy_2024.pdf"
  â†’ status = "active", version = 1

NgÃ y 1/7/2024: Upload "hr_policy_2024_updated.pdf"
  â†’ SimHash phÃ¡t hiá»‡n 90% tÆ°Æ¡ng Ä‘á»“ng vá»›i file cÅ©
  â†’ File cÅ©: status = "superseded"
  â†’ File má»›i: status = "active", version = 2
```

#### BÆ°á»›c 2: Temporal Metadata Propagation
Má»—i chunk káº¿ thá»«a thÃ´ng tin temporal tá»« document:

```python
chunk = {
    "text": "NhÃ¢n viÃªn Ä‘Æ°á»£c nghá»‰ 12 ngÃ y/nÄƒm",
    "upload_timestamp": 1704067200,  # Unix timestamp
    "document_status": "active",      # active/superseded/archived
    "document_version": 2
}
```

#### BÆ°á»›c 3: Recency Scoring trong Retrieval
Khi query, má»—i chunk Ä‘Æ°á»£c tÃ­nh recency score dá»±a trÃªn 3 modes:

##### Mode 1: Exponential Decay (Máº·c Ä‘á»‹nh - Khuyáº¿n nghá»‹)
**CÃ´ng thá»©c:**
```python
age_days = (current_time - upload_timestamp) / 86400
half_life = 30.0  # NgÃ y
recency_score = exp(-age_days / half_life)
```

**Äáº·c Ä‘iá»ƒm:**
- Giáº£m **mÆ°á»£t mÃ  vÃ  tá»± nhiÃªn** theo thá»i gian
- Document 30 ngÃ y tuá»•i = 50% score
- Document 90 ngÃ y tuá»•i = 12.5% score
- KhÃ´ng bao giá» vá» 0 (luÃ´n cÃ²n má»™t chÃºt giÃ¡ trá»‹)

**Biá»ƒu Ä‘á»“:**
```
Score
1.0 |â—
    |  â—
0.8 |    â—
    |      â—
0.6 |        â—â—
    |           â—â—
0.4 |              â—â—â—
    |                  â—â—â—â—
0.2 |                       â—â—â—â—â—â—
0.0 |_________________________________
    0   15  30  45  60  75  90  days
```

**PhÃ¹ há»£p cho:** Policy updates, documentation, general content.

##### Mode 2: Linear Decay
**CÃ´ng thá»©c:**
```python
max_age = 90.0  # NgÃ y
recency_score = max(0, 1.0 - (age_days / max_age))
```

**Äáº·c Ä‘iá»ƒm:**
- Giáº£m **Ä‘á»u Ä‘áº·n** theo thá»i gian
- Document 45 ngÃ y tuá»•i = 50% score
- Document > 90 ngÃ y = 0% score (bá»‹ loáº¡i hoÃ n toÃ n)

**Biá»ƒu Ä‘á»“:**
```
Score
1.0 |â—
    |  â—â—
0.8 |     â—â—
    |        â—â—
0.6 |           â—â—
    |              â—â—
0.4 |                 â—â—
    |                    â—â—
0.2 |                       â—â—
0.0 |___________________________â—â—â—â—
    0   15  30  45  60  75  90  days
```

**PhÃ¹ há»£p cho:** Content cÃ³ "shelf life" rÃµ rÃ ng (quarterly reports, seasonal content).

##### Mode 3: Step Function
**CÃ´ng thá»©c:**
```python
if age_days < 7:
    recency_score = 1.0      # Ráº¥t má»›i: 100%
elif age_days < 30:
    recency_score = 0.7      # Gáº§n Ä‘Ã¢y: 70%
elif age_days < 90:
    recency_score = 0.4      # CÅ©: 40%
else:
    recency_score = 0.1      # Ráº¥t cÅ©: 10%
```

**Äáº·c Ä‘iá»ƒm:**
- **Discrete levels**, khÃ´ng smooth
- Thresholds rÃµ rÃ ng táº¡i 7/30/90 ngÃ y
- Dá»… giáº£i thÃ­ch vÃ  debug

**Biá»ƒu Ä‘á»“:**
```
Score
1.0 |â—â—â—â—â—â—â—
    |        
0.7 |        â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—
    |
0.4 |                                  â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—â—
    |
0.1 |                                                                  â—â—â—â—â—â—â—â—
0.0 |___________________________________________________________________________
    0     7           30                              90              days
```

**PhÃ¹ há»£p cho:** News, alerts, time-critical content.

#### BÆ°á»›c 4: Káº¿t há»£p vá»›i Hybrid Score
**CÃ´ng thá»©c cuá»‘i cÃ¹ng:**
```python
final_score = (1 - recency_weight) Ã— hybrid_score + recency_weight Ã— recency_score
```

**VÃ­ dá»¥ tÃ­nh toÃ¡n cá»¥ thá»ƒ:**

Giáº£ sá»­ `RECENCY_WEIGHT=0.3`, `RECENCY_MODE=exponential`:

```
Chunk A (tá»« document 60 ngÃ y tuá»•i):
  - hybrid_score = 0.85 (ráº¥t relevant)
  - age_days = 60
  - recency_score = exp(-60/30) = 0.135
  - final_score = 0.7 Ã— 0.85 + 0.3 Ã— 0.135 = 0.595 + 0.041 = 0.636

Chunk B (tá»« document 3 ngÃ y tuá»•i):
  - hybrid_score = 0.70 (khÃ¡ relevant)
  - age_days = 3
  - recency_score = exp(-3/30) = 0.905
  - final_score = 0.7 Ã— 0.70 + 0.3 Ã— 0.905 = 0.490 + 0.272 = 0.762
  
â†’ Chunk B Ä‘Æ°á»£c Æ°u tiÃªn dÃ¹ hybrid_score tháº¥p hÆ¡n vÃ¬ ráº¥t má»›i!
```

### Báº£ng cáº¥u hÃ¬nh Recency Boost

### Báº£ng cáº¥u hÃ¬nh Recency Boost

| Biáº¿n | MÃ´ táº£ chi tiáº¿t | GiÃ¡ trá»‹ máº·c Ä‘á»‹nh | Range | Khuyáº¿n nghá»‹ |
|---|---|---|---|---|
| `RECENCY_WEIGHT` | Trá»ng sá»‘ cá»§a recency trong cÃ´ng thá»©c final score.<br/>â€¢ `0.0`: Táº¯t hoÃ n toÃ n (chá»‰ dÃ¹ng relevance)<br/>â€¢ `0.3`: Default - cÃ¢n báº±ng<br/>â€¢ `0.5`: Maximum - Æ°u tiÃªn máº¡nh content má»›i | `0.3` | `0.0 - 0.5` | â€¢ `0.0` cho textbooks, historical content<br/>â€¢ `0.2-0.3` cho documentation<br/>â€¢ `0.4-0.5` cho news, policy updates |
| `RECENCY_MODE` | Cháº¿ Ä‘á»™ time decay:<br/>â€¢ `exponential`: Smooth, natural decay<br/>â€¢ `linear`: Uniform decrease<br/>â€¢ `step`: Discrete thresholds | `exponential` | 3 modes | â€¢ `exponential` cho general use<br/>â€¢ `linear` cho content cÃ³ shelf life<br/>â€¢ `step` cho time-critical (news) |

### Ma tráº­n Use Cases cho Recency Boost

| Use Case | Scenario | RECENCY_WEIGHT | MODE | LÃ½ do |
|---|---|---|---|---|
| **Policy/HR Updates** | CÃ´ng ty cáº­p nháº­t quy Ä‘á»‹nh hÃ ng quÃ½/nÄƒm | `0.4-0.5` | `exponential` | PhiÃªn báº£n má»›i luÃ´n Æ°u tiÃªn, cÅ© giáº£m dáº§n |
| **News/Blog** | Tin tá»©c cÃ´ng nghá»‡, blog hÃ ng tuáº§n | `0.5` | `step` | Content > 1 tuáº§n = outdated |
| **Technical Docs** | API docs, user guides cÃ³ updates | `0.3` | `exponential` | CÃ¢n báº±ng giá»¯a relevance vÃ  recency |
| **Legal/Compliance** | VÄƒn báº£n phÃ¡p luáº­t, compliance docs | `0.4` | `exponential` | Luáº­t má»›i thay tháº¿ luáº­t cÅ© |
| **Research Papers** | BÃ i bÃ¡o khoa há»c, literature review | `0.2` | `linear` | Paper gá»‘c váº«n quan trá»ng dÃ¹ cÅ© |
| **Historical Archives** | SÃ¡ch lá»‹ch sá»­, tÃ i liá»‡u lÆ°u trá»¯ | `0.0` | (any) | ThÃ´ng tin khÃ´ng phá»¥ thuá»™c thá»i gian |
| **Product Catalog** | Danh má»¥c sáº£n pháº©m, price list | `0.4` | `linear` | GiÃ¡ cÅ© khÃ´ng cÃ²n valid sau 90 ngÃ y |

### Workflow thá»±c táº¿: Policy Update Scenario

**TÃ¬nh huá»‘ng:** CÃ´ng ty cÃ³ policy nghá»‰ phÃ©p Ä‘Æ°á»£c cáº­p nháº­t hÃ ng nÄƒm.

**Timeline:**
```
ğŸ“… 01/01/2024: Upload hr_policy_2024.pdf
  â”œâ”€ Status: active
  â”œâ”€ Version: 1
  â””â”€ Ná»™i dung: "NhÃ¢n viÃªn Ä‘Æ°á»£c nghá»‰ 12 ngÃ y/nÄƒm"

ğŸ“… 15/06/2024: NhÃ¢n viÃªn há»i: "TÃ´i Ä‘Æ°á»£c nghá»‰ bao nhiÃªu ngÃ y?"
  â””â”€ Tráº£ lá»i: "12 ngÃ y/nÄƒm" [hr_policy_2024.pdf:5] âœ¨ Má»›i

ğŸ“… 01/01/2025: Upload hr_policy_2025.pdf
  â”œâ”€ SimHash detect: 85% similar to 2024 version
  â”œâ”€ Action: Mark 2024 as "superseded"
  â”œâ”€ New document:
  â”‚   â”œâ”€ Status: active
  â”‚   â”œâ”€ Version: 2
  â”‚   â””â”€ Ná»™i dung: "NhÃ¢n viÃªn Ä‘Æ°á»£c nghá»‰ 15 ngÃ y/nÄƒm" (tÄƒng lÃªn!)

ğŸ“… 02/01/2025: NhÃ¢n viÃªn há»i láº¡i cÃ¢u cÅ©: "TÃ´i Ä‘Æ°á»£c nghá»‰ bao nhiÃªu ngÃ y?"
  â””â”€ Há»‡ thá»‘ng tá»± Ä‘á»™ng Æ°u tiÃªn version 2025:
      - Chunk from 2024: recency_score = 0.37 (1 nÄƒm tuá»•i)
      - Chunk from 2025: recency_score = 1.0 (1 ngÃ y tuá»•i)
  â””â”€ Tráº£ lá»i: "15 ngÃ y/nÄƒm" [hr_policy_2025.pdf:5] âœ¨ Má»›i
```

**UI hiá»ƒn thá»‹:**
```
ğŸ“„ Sources:
[1] hr_policy_2025.pdf:5 | âœ¨ Má»›i | ğŸ“… 1 ngÃ y trÆ°á»›c | Recency: 100%
    "NhÃ¢n viÃªn Ä‘Æ°á»£c nghá»‰ 15 ngÃ y/nÄƒm..."
    
[2] hr_policy_2024.pdf:5 | ğŸ“ CÅ© | ğŸ“… 1 nÄƒm trÆ°á»›c | Recency: 37%
    "NhÃ¢n viÃªn Ä‘Æ°á»£c nghá»‰ 12 ngÃ y/nÄƒm..."
```

### Troubleshooting Recency Boost

#### Problem 1: Document má»›i khÃ´ng Ä‘Æ°á»£c Æ°u tiÃªn
**Triá»‡u chá»©ng:** Chunk tá»« file má»›i cÃ³ recency_score = 1.0 nhÆ°ng váº«n rank tháº¥p.

**NguyÃªn nhÃ¢n cÃ³ thá»ƒ:**
1. `RECENCY_WEIGHT` quÃ¡ tháº¥p (vÃ­ dá»¥ 0.1)
2. Hybrid score cá»§a chunk cÅ© quÃ¡ cao (0.95+)

**Giáº£i phÃ¡p:**
```ini
# TÄƒng RECENCY_WEIGHT lÃªn
RECENCY_WEIGHT=0.4  # hoáº·c 0.5

# Hoáº·c kiá»ƒm tra láº¡i relevance cá»§a cÃ¢u há»i
# CÃ³ thá»ƒ chunk cÅ© thá»±c sá»± relevant hÆ¡n vá»›i cÃ¢u há»i cá»¥ thá»ƒ
```

**CÃ¡ch debug:**
```python
# Kiá»ƒm tra scores trong response
{
  "sources": [
    {
      "doc": "new_doc.pdf",
      "hybrid_score": 0.65,      # Relevance tháº¥p
      "recency_score": 1.0,       # Ráº¥t má»›i
      "final_score": 0.755        # = 0.7*0.65 + 0.3*1.0
    },
    {
      "doc": "old_doc.pdf",
      "hybrid_score": 0.92,       # Relevance cao!
      "recency_score": 0.37,      # CÅ©
      "final_score": 0.755        # = 0.7*0.92 + 0.3*0.37
    }
  ]
}
# â†’ Cáº£ hai báº±ng nhau! Cáº§n tÄƒng RECENCY_WEIGHT
```

#### Problem 2: Document cÅ© bá»‹ ignore hoÃ n toÃ n
**Triá»‡u chá»©ng:** Chunk tá»« file cÅ© cÃ³ hybrid_score = 0.95 nhÆ°ng khÃ´ng Ä‘Æ°á»£c chá»n.

**NguyÃªn nhÃ¢n:** `RECENCY_WEIGHT` quÃ¡ cao hoáº·c dÃ¹ng `step` mode vá»›i threshold quÃ¡ strict.

**Giáº£i phÃ¡p:**
```ini
# Giáº£m RECENCY_WEIGHT
RECENCY_WEIGHT=0.2

# Hoáº·c chuyá»ƒn sang exponential mode
RECENCY_MODE=exponential
```

#### Problem 3: Version detection sai
**Triá»‡u chá»©ng:** File má»›i hoÃ n toÃ n khÃ¡c nhÆ°ng bá»‹ mark lÃ  "superseded" cá»§a file cÅ©.

**NguyÃªn nhÃ¢n:** SimHash threshold quÃ¡ cao (>30 bits).

**Giáº£i phÃ¡p:** Cáº§n Ä‘iá»u chá»‰nh threshold trong code `document_tracker.py`:
```python
# Default: 20 bits
if hamming_distance < 20:  # Giáº£m xuá»‘ng 15 Ä‘á»ƒ strict hÆ¡n
    mark_as_superseded()
```

---

## ğŸ§  Sinh cÃ¢u tráº£ lá»i thÃ´ng minh (Generative AI)

### Tá»•ng quan

Sá»­ dá»¥ng **Gemini 2.0 Flash** Ä‘á»ƒ táº¡o cÃ¢u tráº£ lá»i dá»±a trÃªn ngá»¯ cáº£nh Ä‘Ã£ retrieval, vá»›i cÃ¡c cÆ¡ cháº¿ báº£o vá»‡ (guardrails) Ä‘á»ƒ tÄƒng Ä‘á»™ tin cáº­y vÃ  giáº£m hallucination.

### Pipeline Generation chi tiáº¿t

#### BÆ°á»›c 1: Context Assembly
Sau khi retrieval, há»‡ thá»‘ng ghÃ©p cÃ¡c chunks thÃ nh context:

```python
context = ""
for i, chunk in enumerate(top_chunks):
    context += f"[{i+1}] ({chunk.doc}:page {chunk.page})\n"
    context += f"{chunk.text}\n\n"
```

**VÃ­ dá»¥ context:**
```
[1] (hr_policy.pdf:page 5)
NhÃ¢n viÃªn chÃ­nh thá»©c Ä‘Æ°á»£c hÆ°á»Ÿng 15 ngÃ y nghá»‰ phÃ©p cÃ³ lÆ°Æ¡ng hÃ ng nÄƒm.
NhÃ¢n viÃªn thá»­ viá»‡c Ä‘Æ°á»£c hÆ°á»Ÿng 7 ngÃ y nghá»‰ phÃ©p.

[2] (hr_policy.pdf:page 6)
Nghá»‰ phÃ©p cáº§n Ä‘Äƒng kÃ½ trÆ°á»›c tá»‘i thiá»ƒu 3 ngÃ y lÃ m viá»‡c.
TrÆ°á»ng há»£p kháº©n cáº¥p, thÃ´ng bÃ¡o cho quáº£n lÃ½ trá»±c tiáº¿p.
```

#### BÆ°á»›c 2: Prompt Engineering
Há»‡ thá»‘ng táº¡o prompt vá»›i 3 pháº§n chÃ­nh:

**1. System Instruction:**
```
Báº¡n lÃ  trá»£ lÃ½ AI chuyÃªn tráº£ lá»i cÃ¢u há»i dá»±a trÃªn tÃ i liá»‡u Ä‘Æ°á»£c cung cáº¥p.
QUAN TRá»ŒNG:
- CHá»ˆ tráº£ lá»i dá»±a trÃªn ngá»¯ cáº£nh Ä‘Æ°á»£c cung cáº¥p
- Báº®T BUá»˜C trÃ­ch dáº«n nguá»“n [doc:page]
- Náº¾U khÃ´ng cÃ³ thÃ´ng tin: nÃ³i "TÃ´i khÃ´ng tÃ¬m tháº¥y..."
```

**2. Context:**
```
=== NGá»® Cáº¢NH ===
[1] (hr_policy.pdf:page 5)
...
```

**3. User Query:**
```
=== CÃ‚U Há»I ===
NhÃ¢n viÃªn thá»­ viá»‡c Ä‘Æ°á»£c nghá»‰ bao nhiÃªu ngÃ y?
```

#### BÆ°á»›c 3: LLM Generation
Gá»i Gemini API vá»›i parameters:

```python
response = gemini.generate_content(
    prompt,
    temperature=0.08,           # Ráº¥t tháº¥p Ä‘á»ƒ deterministic
    max_output_tokens=1024,     # Äá»§ cho cÃ¢u tráº£ lá»i chi tiáº¿t
    top_p=0.95,                 # Nucleus sampling
    top_k=40                    # Top-K sampling
)
```

**Temperature impact:**
```
Temperature = 0.0 (Deterministic):
  "NhÃ¢n viÃªn thá»­ viá»‡c Ä‘Æ°á»£c hÆ°á»Ÿng 7 ngÃ y nghá»‰ phÃ©p. [hr_policy.pdf:5]"
  â†’ CÃ¢u tráº£ lá»i giá»‘ng nhau má»i láº§n

Temperature = 0.08 (Default):
  "Theo chÃ­nh sÃ¡ch, nhÃ¢n viÃªn thá»­ viá»‡c Ä‘Æ°á»£c hÆ°á»Ÿng 7 ngÃ y nghá»‰ phÃ©p cÃ³ lÆ°Æ¡ng. [hr_policy.pdf:5]"
  â†’ CÃ³ variation nháº¹ nhÆ°ng váº«n chÃ­nh xÃ¡c

Temperature = 0.5 (Cao):
  "NhÃ¢n viÃªn Ä‘ang trong thá»i gian thá»­ viá»‡c sáº½ Ä‘Æ°á»£c nghá»‰ 7 ngÃ y trong nÄƒm, Ã­t hÆ¡n so vá»›i nhÃ¢n viÃªn chÃ­nh thá»©c. [hr_policy.pdf:5]"
  â†’ ThÃªm suy luáº­n, cÃ³ thá»ƒ hallucinate
```

#### BÆ°á»›c 4: Guardrails - Kiá»ƒm tra cháº¥t lÆ°á»£ng

**Guardrail 1: Minimum Similarity Check**
```python
if max_similarity < GENERATE_MIN_SIM:  # Default: 0.25
    return "TÃ´i khÃ´ng tÃ¬m tháº¥y thÃ´ng tin liÃªn quan Ä‘áº¿n cÃ¢u há»i cá»§a báº¡n."
```

**VÃ­ dá»¥:**
```
Query: "CÃ´ng thá»©c tÃ­nh tá»‘c Ä‘á»™ Ã¡nh sÃ¡ng?"
Top chunk similarity: 0.15 (vá» policy cÃ´ng ty, khÃ´ng liÃªn quan)
â†’ Há»† THá»NG Tá»ª CHá»I TRáº¢ Lá»œI thay vÃ¬ hallucinate
```

**Guardrail 2: Answer Confidence Check**
Sau khi cÃ³ cÃ¢u tráº£ lá»i, há»‡ thá»‘ng Ä‘Ã¡nh giÃ¡ confidence:

```python
confidence_prompt = f"""
Context: {context}
Question: {query}
Answer: {answer}

On a scale 0-1, how confident are you that this answer is:
1. Based on the provided context (context_prob)
2. Directly answering the question (direct_prob)
"""

if context_prob < ANSWER_MIN_CONTEXT_PROB:  # 0.35
    return "ThÃ´ng tin khÃ´ng Ä‘á»§ tin cáº­y..."
    
if direct_prob < ANSWER_MIN_DIRECT_PROB:  # 0.25
    return "CÃ¢u tráº£ lá»i khÃ´ng trá»±c tiáº¿p..."
```

**Guardrail 3: Citation Validation**
Kiá»ƒm tra cÃ¢u tráº£ lá»i cÃ³ trÃ­ch dáº«n nguá»“n khÃ´ng:

```python
import re
citations = re.findall(r'\[([^\]]+):(\d+)\]', answer)
if not citations:
    logger.warning("Answer missing citations!")
    # CÃ³ thá»ƒ reject hoáº·c warn user
```

### Báº£ng cáº¥u hÃ¬nh Generation

| Biáº¿n | MÃ´ táº£ | GiÃ¡ trá»‹ máº·c Ä‘á»‹nh |
|---|---|---|
| `RAG_LLM_MODEL` | Model Gemini dÃ¹ng Ä‘á»ƒ sinh cÃ¢u tráº£ lá»i. | `gemini-2.0-flash-001` |
| `GENERATE_MIN_SIM` | NgÆ°á»¡ng tÆ°Æ¡ng Ä‘á»“ng tá»‘i thiá»ƒu giá»¯a cÃ¢u há»i vÃ  ngá»¯ cáº£nh. Náº¿u tháº¥p hÆ¡n, há»‡ thá»‘ng tá»« chá»‘i tráº£ lá»i. | `0.25` |
| `ANSWER_MIN_CONTEXT_PROB` | NgÆ°á»¡ng tin cáº­y tá»‘i thiá»ƒu mÃ  cÃ¢u tráº£ lá»i pháº£i dá»±a trÃªn ngá»¯ cáº£nh Ä‘Æ°á»£c cung cáº¥p. | `0.35` |
| `ANSWER_MIN_DIRECT_PROB` | NgÆ°á»¡ng tin cáº­y tá»‘i thiá»ƒu cho cÃ¡c cÃ¢u tráº£ lá»i trá»±c tiáº¿p (khÃ´ng cáº§n suy luáº­n phá»©c táº¡p). | `0.25` |
| `GEN_TEMPERATURE` | Äá»™ "sÃ¡ng táº¡o" cá»§a model. `0.0` cho cÃ¢u tráº£ lá»i xÃ¡c Ä‘á»‹nh, cao hÆ¡n sáº½ Ä‘a dáº¡ng hÆ¡n. | `0.08` |
| `GEN_MAX_OUTPUT_TOKENS` | Sá»‘ lÆ°á»£ng token tá»‘i Ä‘a cho má»™t cÃ¢u tráº£ lá»i. | `1024` |

---

## ğŸ“¤ Quáº£n lÃ½ vÃ  xá»­ lÃ½ tÃ i liá»‡u

Há»‡ thá»‘ng Ä‘Æ°á»£c tá»‘i Æ°u Ä‘á»ƒ xá»­ lÃ½ file PDF, bao gá»“m cáº£ tÃ i liá»‡u scan.

- **Upload Ä‘a file**: Há»— trá»£ táº£i lÃªn nhiá»u file PDF cÃ¹ng lÃºc.
- **OCR tÃ­ch há»£p**: Tá»± Ä‘á»™ng dÃ¹ng `Tesseract OCR` Ä‘á»ƒ trÃ­ch xuáº¥t chá»¯ tá»« file áº£nh/scan.
- **Chunking thÃ´ng minh**: Chia nhá» vÄƒn báº£n Ä‘á»ƒ tá»‘i Æ°u cho viá»‡c tÃ¬m kiáº¿m.
- **Session Isolation**: Má»—i phiÃªn chat cÃ³ má»™t khÃ´ng gian tÃ i liá»‡u riÃªng.

### Cáº¥u hÃ¬nh (`.env`)

| Biáº¿n | MÃ´ táº£ | GiÃ¡ trá»‹ máº·c Ä‘á»‹nh |
|---|---|---|
| `MAX_FILES` | Sá»‘ lÆ°á»£ng file tá»‘i Ä‘a cho má»™t láº§n upload. | `5` |
| `MAX_FILE_MB` | Dung lÆ°á»£ng tá»‘i Ä‘a cho má»—i file (tÃ­nh báº±ng MB). | `10` |
| `TESSERACT_CMD` | ÄÆ°á»ng dáº«n Ä‘áº¿n file thá»±c thi cá»§a Tesseract OCR. | `C:\ Program Files\Tesseract-OCR\tesseract.exe` |
| `OCR_LANG` | NgÃ´n ngá»¯ Æ°u tiÃªn cho OCR (vÃ­ dá»¥: `vie` cho tiáº¿ng Viá»‡t, `eng` cho tiáº¿ng Anh). | `vie` |

---

## âš¡ Tá»‘i Æ°u Hiá»‡u nÄƒng & Cache

### Tá»•ng quan

Há»‡ thá»‘ng tÃ­ch há»£p **hai lá»›p cache** Ä‘á»ƒ:
- Giáº£m latency (thá»i gian pháº£n há»“i)
- Tiáº¿t kiá»‡m chi phÃ­ API calls
- TÄƒng throughput (sá»‘ request/giÃ¢y)

### Cache Layer 1: Embedding Cache

#### Má»¥c Ä‘Ã­ch
LÆ°u trá»¯ embeddings Ä‘Ã£ tÃ­nh toÃ¡n Ä‘á»ƒ trÃ¡nh gá»i Gemini API láº¡i cho cÃ¹ng má»™t Ä‘oáº¡n text.

#### CÃ¡ch hoáº¡t Ä‘á»™ng

```python
def get_or_compute_embedding(text: str) -> np.ndarray:
    # 1. TÃ­nh hash cá»§a text
    text_hash = hashlib.sha256(text.encode()).hexdigest()
    
    # 2. Kiá»ƒm tra cache
    cached = cache_db.get(text_hash)
    if cached:
        logger.info("âœ… Cache hit!")
        return np.frombuffer(cached, dtype=np.float32)
    
    # 3. Náº¿u miss, gá»i API
    logger.info("âŒ Cache miss, calling Gemini API...")
    embedding = gemini.embed_content(text)
    
    # 4. LÆ°u vÃ o cache
    cache_db.set(text_hash, embedding.tobytes())
    
    return embedding
```

#### Performance Impact

**Scenario: Re-ingest document sau khi chá»‰nh sá»­a nhá»**

KhÃ´ng cÃ³ cache:
```
Document: 100 pages, 350 chunks
API calls: 350 requests
Time: 350 Ã— 0.3s = 105 seconds
Cost: 350 Ã— $0.00001 = $0.0035
```

CÃ³ cache (90% chunks khÃ´ng Ä‘á»•i):
```
Cache hits: 315 chunks (90%)
API calls: 35 requests (10% new/modified)
Time: 35 Ã— 0.3s + 315 Ã— 0.001s = 10.8 seconds  â† 10x faster!
Cost: 35 Ã— $0.00001 = $0.00035  â† 10x cheaper!
```

#### Cache Storage

**Schema SQLite:**
```sql
CREATE TABLE embedding_cache (
    text_hash TEXT PRIMARY KEY,
    embedding BLOB,           -- 768 Ã— 4 bytes = 3KB per entry
    model_name TEXT,
    created_at TIMESTAMP,
    access_count INTEGER
);

CREATE INDEX idx_created ON embedding_cache(created_at);
```

**Capacity estimate:**
```
Average chunk: 300 tokens â‰ˆ 225 words
Embedding size: 768 floats Ã— 4 bytes = 3KB
1000 chunks = 3 MB
10,000 chunks = 30 MB
100,000 chunks = 300 MB â† Very manageable!
```

#### Cache Invalidation Strategy

**Khi nÃ o cáº§n clear cache:**
1. **Model upgrade:** `text-embedding-004` â†’ `text-embedding-005`
2. **Dimension change:** 768 â†’ 1024 dims
3. **Disk space issue:** Cache DB > 1GB

**Commands:**
```bash
# Clear toÃ n bá»™ cache
rm ./storage/emb_cache/*.sqlite

# Clear cache cÅ© hÆ¡n 30 ngÃ y
python scripts/clean_old_cache.py --days 30

# Check cache stats
python -c "
from app.rag.cache import EmbeddingCache
cache = EmbeddingCache()
print(f'Entries: {cache.count()}')
print(f'Hit rate: {cache.hit_rate():.1%}')
print(f'Size: {cache.size_mb():.1f} MB')
"
```

### Cache Layer 2: Answer Cache

#### Má»¥c Ä‘Ã­ch
LÆ°u cÃ¢u tráº£ lá»i Ä‘Ã£ generate cho cÃ¹ng má»™t cáº·p (query, document_set).

#### CÃ¡ch hoáº¡t Ä‘á»™ng

```python
def get_or_generate_answer(query: str, doc_ids: List[str]) -> str:
    # 1. TÃ­nh cache key
    cache_key = hashlib.md5(
        f"{query}:{sorted(doc_ids)}".encode()
    ).hexdigest()
    
    # 2. Check cache
    cached_answer = answer_cache.get(cache_key)
    if cached_answer and not is_expired(cached_answer, max_age=3600):
        logger.info("âœ… Answer cache hit!")
        return cached_answer['answer']
    
    # 3. Generate new answer
    answer = generate_with_llm(query, contexts)
    
    # 4. Cache with metadata
    answer_cache.set(cache_key, {
        'answer': answer,
        'query': query,
        'doc_ids': doc_ids,
        'timestamp': time.time(),
        'confidence': confidence_score
    })
    
    return answer
```

#### Cache Hit Scenarios

**Scenario 1: Repeated questions**
```
User A (10:00): "Quy Ä‘á»‹nh nghá»‰ phÃ©p?"
  â†’ Generate answer, cache it

User B (10:05): "Quy Ä‘á»‹nh nghá»‰ phÃ©p?"  â† Exact same query!
  â†’ Cache hit! Return instantly
  
Time saved: ~2 seconds per query
```

**Scenario 2: Similar questions (advanced)**
```python
# With fuzzy matching (optional)
def find_similar_cached_query(new_query: str, threshold=0.95):
    for cached in answer_cache.all():
        similarity = cosine_sim(
            embed(new_query),
            embed(cached['query'])
        )
        if similarity > threshold:
            return cached['answer']
    return None
```

#### Cache Expiration Policy

**TTL (Time To Live) strategy:**
```ini
# .env configuration
ANSWER_CACHE_TTL=3600  # 1 hour default

# Dynamic TTL based on content:
if document_status == "active":
    ttl = 3600  # 1 hour
elif document_status == "superseded":
    ttl = 0     # Don't cache old content
```

**Invalidation triggers:**
1. **New document uploaded** â†’ Clear cache for that session
2. **Document deleted** â†’ Clear related cache entries
3. **Manual clear** â†’ User action via API

### Báº£ng cáº¥u hÃ¬nh Performance & Cache

| Biáº¿n | MÃ´ táº£ chi tiáº¿t | GiÃ¡ trá»‹ máº·c Ä‘á»‹nh | Khuyáº¿n nghá»‹ |
|---|---|---|---|
| `ENABLE_EMBED_CACHE` | Báº­t/táº¯t Embedding Cache.<br/>**Highly recommended** luÃ´n báº­t! | `true` | LuÃ´n `true` trá»« khi debugging |
| `EMBED_CACHE_DB` | ÄÆ°á»ng dáº«n SQLite database cho embedding cache | `./storage/embed_cache.sqlite` | SSD path Ä‘á»ƒ nhanh hÆ¡n |
| `ENABLE_ANSWER_CACHE` | Báº­t/táº¯t Answer Cache.<br/>Táº¯t náº¿u cáº§n cÃ¢u tráº£ lá»i luÃ´n má»›i | `true` | â€¢ `true` cho production<br/>â€¢ `false` náº¿u content thay Ä‘á»•i liÃªn tá»¥c |
| `ANSWER_CACHE_DB` | ÄÆ°á»ng dáº«n SQLite database cho answer cache | `./storage/answer_cache.sqlite` | SSD path Ä‘á»ƒ nhanh hÆ¡n |
| `ANSWER_CACHE_TTL` | Time-to-live cho cached answers (giÃ¢y) | `3600` | â€¢ `3600` (1h) cho general<br/>â€¢ `600` (10m) cho content Ä‘á»™ng<br/>â€¢ `86400` (24h) cho static content |
| `EMBED_CONCURRENCY` | Sá»‘ threads parallel cho embedding generation | `4` | â€¢ `2-4` cho mÃ¡y yáº¿u<br/>â€¢ `8-16` cho server máº¡nh |
| `EMBED_SLEEP_MS` | Delay giá»¯a cÃ¡c API calls (trÃ¡nh rate limit) | `0` | â€¢ `0` náº¿u cÃ³ quota cao<br/>â€¢ `100-200` náº¿u bá»‹ rate limit |

### Performance Tuning Matrix

| Scenario | Cache Config | Expected Performance |
|---|---|---|
| **Development** | Both caches ON | â€¢ Initial ingest: 100s<br/>â€¢ Re-ingest: 10s (10x faster)<br/>â€¢ Query: 1.5s avg |
| **Production - High Traffic** | Both caches ON, TTL=3600 | â€¢ Cache hit rate: 60-80%<br/>â€¢ Avg latency: 0.8s<br/>â€¢ API cost: -70% |
| **Production - Low Traffic** | Embed cache ON, Answer cache OFF | â€¢ Fresh answers always<br/>â€¢ Moderate API usage |
| **Testing/Debug** | Both caches OFF | â€¢ Clean state every run<br/>â€¢ Higher latency & cost |

### Monitoring Cache Performance

**Metrics to track:**

```python
# app/utils/monitoring.py
class CacheMetrics:
    def __init__(self):
        self.embed_hits = 0
        self.embed_misses = 0
        self.answer_hits = 0
        self.answer_misses = 0
    
    @property
    def embed_hit_rate(self):
        total = self.embed_hits + self.embed_misses
        return self.embed_hits / total if total > 0 else 0
    
    @property
    def answer_hit_rate(self):
        total = self.answer_hits + self.answer_misses
        return self.answer_hits / total if total > 0 else 0
```

**Dashboard example:**
```
=== Cache Performance (Last 24h) ===
Embedding Cache:
  Hits: 15,234 | Misses: 3,456 | Hit Rate: 81.5%
  API Calls Saved: 15,234
  Cost Saved: $0.15

Answer Cache:
  Hits: 892 | Misses: 1,108 | Hit Rate: 44.6%
  Avg Response Time: 0.7s (vs 2.1s without cache)
  
Total Savings: $0.17/day â‰ˆ $5.10/month
```

---

## ğŸ’¬ Quáº£n lÃ½ Há»™i thoáº¡i vÃ  Giao diá»‡n

### Session Management

**Features:**
- **Multi-session support**: Má»—i user cÃ³ thá»ƒ cÃ³ nhiá»u chat sessions
- **Session persistence**: LÆ°u trá»¯ session metadata vÃ  chat history
- **Easy navigation**: Sidebar Ä‘á»ƒ chuyá»ƒn Ä‘á»•i giá»¯a cÃ¡c sessions
- **Auto-restore**: Tá»± Ä‘á»™ng má»Ÿ láº¡i session gáº§n nháº¥t khi quay láº¡i

### UI Components

#### 1. Sidebar - Session List
```javascript
// Display all sessions
sessions.forEach(session => {
    renderSessionCard({
        title: session.title || "Chat má»›i",
        message_count: session.message_count,
        last_active: session.last_active,
        status: session.status  // active/superseded/archived
    });
});
```

#### 2. Chat Interface
**Features:**
- Real-time typing indicator
- Message streaming (náº¿u supported)
- Citation highlighting
- Document source badges (âœ¨ Má»›i, ğŸ“ CÅ©, ğŸ“¦ Archive)

#### 3. File Management Panel
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ“„ Uploaded Documents               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ âœ… hr_policy_2025.pdf  (24 KB)     â”‚
â”‚    âœ¨ Má»›i | 1 ngÃ y trÆ°á»›c            â”‚
â”‚    [View] [Delete]                  â”‚
â”‚                                      â”‚
â”‚ âœ… company_handbook.pdf (156 KB)   â”‚
â”‚    ğŸ“ CÅ© | 3 thÃ¡ng trÆ°á»›c            â”‚
â”‚    [View] [Delete]                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Best Practices

**For End Users:**
1. **Organize by topic**: Táº¡o session riÃªng cho má»—i chá»§ Ä‘á» (HR, Technical, Finance)
2. **Regular cleanup**: XÃ³a sessions cÅ© khÃ´ng dÃ¹ng Ä‘á»ƒ tiáº¿t kiá»‡m storage
3. **Descriptive titles**: Äáº·t tÃªn session rÃµ rÃ ng ("HR Policy Q&A", "API Documentation")

**For Admins:**
```bash
# Cleanup old sessions (>30 days inactive)
python scripts/cleanup_sessions.py --days 30

# Export session data
python scripts/export_session.py --session_id xxx --format json

# Backup all sessions
tar -czf sessions_backup_$(date +%Y%m%d).tar.gz ./uploads/
```

---

## ğŸ“Š Summary: Configuration Quick Reference

### Must-Have Settings (Tá»‘i thiá»ƒu)

```ini
# === Core AI ===
GEMINI_API_KEY=your_actual_key
RAG_EMBED_MODEL=text-embedding-004
RAG_LLM_MODEL=gemini-2.0-flash-001

# === Essential Performance ===
ENABLE_EMBED_CACHE=true
ENABLE_ANSWER_CACHE=true

# === Balanced Retrieval ===
HYBRID_ON=true
HYBRID_ALPHA=0.6
CONTEXT_K=10
```

### Recommended Production Settings

```ini
# === Optimized for Accuracy ===
HYBRID_ALPHA=0.6
RETRIEVE_TOP_K=12
CONTEXT_K=10
MMR_LAMBDA=0.7
RERANK_ON=true

# === Optimized for Recency ===
RECENCY_WEIGHT=0.3
RECENCY_MODE=exponential

# === Optimized for Safety ===
GENERATE_MIN_SIM=0.25
ANSWER_MIN_CONTEXT_PROB=0.35
GEN_TEMPERATURE=0.08

# === Optimized for Performance ===
ENABLE_EMBED_CACHE=true
ENABLE_ANSWER_CACHE=true
EMBED_CONCURRENCY=4
```

### Emergency "Fix It" Configs

**Problem: Too many hallucinations**
```ini
GEN_TEMPERATURE=0.05         # More deterministic
GENERATE_MIN_SIM=0.30        # Stricter threshold
ANSWER_MIN_CONTEXT_PROB=0.40
```

**Problem: Too slow**
```ini
RERANK_ON=false              # Disable reranker
CONTEXT_K=6                  # Less context
RETRIEVE_TOP_K=8
GEN_MAX_OUTPUT_TOKENS=512
```

**Problem: Over-rejecting questions**
```ini
GENERATE_MIN_SIM=0.20        # Lower threshold
ANSWER_MIN_CONTEXT_PROB=0.30
HYBRID_ALPHA=0.5             # More semantic search
```

---

## ğŸ“ Learning Path: From Beginner to Expert

### Level 1: Basic Usage (NgÆ°á»i dÃ¹ng cÆ¡ báº£n)
âœ… Upload PDF vÃ  Ä‘áº·t cÃ¢u há»i  
âœ… Hiá»ƒu cÃ¡ch Ä‘á»c trÃ­ch dáº«n `[doc:page]`  
âœ… Biáº¿t khi nÃ o nÃªn dÃ¹ng OCR

### Level 2: Configuration Tuning (NgÆ°á»i dÃ¹ng nÃ¢ng cao)
âœ… Äiá»u chá»‰nh `HYBRID_ALPHA` theo loáº¡i tÃ i liá»‡u  
âœ… Tuning `RECENCY_WEIGHT` cho use case cá»¥ thá»ƒ  
âœ… Hiá»ƒu trade-off giá»¯a accuracy vÃ  speed

### Level 3: Advanced Optimization (Power User)
âœ… Monitoring cache hit rates  
âœ… Custom chunking strategies  
âœ… A/B testing different configurations

### Level 4: System Administration (Admin/DevOps)
âœ… Performance profiling vá»›i metrics  
âœ… Database optimization vÃ  backup  
âœ… Multi-user deployment vÃ  scaling

---

**TÃ i liá»‡u nÃ y sáº½ Ä‘Æ°á»£c cáº­p nháº­t liÃªn tá»¥c. HÃ£y check láº¡i thÆ°á»ng xuyÃªn Ä‘á»ƒ cÃ³ thÃ´ng tin má»›i nháº¥t! ğŸš€**