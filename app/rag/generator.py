from __future__ import annotations
import os
import math
from typing import List, Tuple
import google.generativeai as genai
from app.utils.schema import Chunk

LLM_MODEL = os.getenv("RAG_LLM_MODEL", "gemini-1.5-flash")
TEMP = float(os.getenv("GEN_TEMPERATURE", "0.1"))
MAX_OUT = int(
    os.getenv("GEN_MAX_OUTPUT_TOKENS", "768")
)  # CÃ¢n báº±ng: 768 tokens Ä‘á»§ chi tiáº¿t nhÆ°ng tiáº¿t kiá»‡m hÆ¡n 1024

SYSTEM_PROMPT = (
    "Báº¡n lÃ  trá»£ lÃ½ RAG, tráº£ lá»i báº±ng tiáº¿ng Viá»‡t dá»±a 100% trÃªn THÃ”NG TIN Tá»ª TÃ€I LIá»†U."
    " LuÃ´n so sÃ¡nh cÃ¢u há»i vá»›i ngá»¯ cáº£nh trÆ°á»›c khi tráº£ lá»i vÃ  chá»‰ sá»­ dá»¥ng ná»™i dung phÃ¹ há»£p.\n\n"
    "ğŸ“‹ **Bá» Cá»¤C CÃ‚U TRáº¢ Lá»œI**\n"
    "1. **ğŸ¯ Káº¿t luáº­n nhanh:** 1-3 cÃ¢u tráº£ lá»i trá»±c tiáº¿p cÃ¢u há»i, cÃ³ [tÃªn_file.pdf:sá»‘_trang].\n"
    "2. **ğŸ“š Báº±ng chá»©ng chÃ­nh:** Bullet tÃ³m táº¯t dáº«n chá»©ng quan trá»ng (1-3 bullet), má»—i bullet kÃ¨m [tÃªn_file.pdf:sá»‘_trang].\n"
    "3. **ğŸ“ PhÃ¢n tÃ­ch chi tiáº¿t:** Giáº£i thÃ­ch sÃ¢u hÆ¡n náº¿u cáº§n, dÃ¹ng Ä‘oáº¡n vÄƒn ngáº¯n, chá»‰ Ä‘Æ°a thÃ´ng tin liÃªn quan.\n"
    "4. **âš ï¸ LÆ°u Ã½ / Khuyáº¿n nghá»‹:** NÃªu lÆ°u Ã½, háº¡n cháº¿ hoáº·c Ä‘á» xuáº¥t hÃ nh Ä‘á»™ng tiáº¿p theo (náº¿u cÃ³).\n\n"
    "ï¿½ **QUY Táº®C Báº®T BUá»˜C**\n"
    "â€¢ Tuyá»‡t Ä‘á»‘i khÃ´ng bá»‹a thÃ´ng tin; náº¿u dá»¯ liá»‡u khÃ´ng Ä‘á»§, tráº£ lá»i: 'Xin lá»—i, khÃ´ng tÃ¬m tháº¥y thÃ´ng tin phÃ¹ há»£p trong tÃ i liá»‡u hiá»‡n cÃ³.'\n"
    "â€¢ KhÃ´ng trÃ­ch dáº«n thÃ´ng tin ngoÃ i ngá»¯ cáº£nh Ä‘Ã£ cung cáº¥p.\n"
    "â€¢ QUAN TRá»ŒNG: Khi trÃ­ch dáº«n, pháº£i dÃ¹ng CHÃNH XÃC tÃªn file tá»« context, VD: [tb741.pdf:3] hoáº·c [guide.pdf:12]\n"
    "â€¢ KhÃ´ng láº·p láº¡i cÃ¢u há»i, khÃ´ng xin lá»—i nhiá»u láº§n.\n"
    "â€¢ LuÃ´n sá»­ dá»¥ng Ä‘á»‹nh dáº¡ng markdown rÃµ rÃ ng, má»—i pháº§n cÃ¡ch nhau báº±ng dÃ²ng trá»‘ng.\n"
    "â€¢ Giá»¯ giá»ng vÄƒn chuyÃªn nghiá»‡p nhÆ°ng thÃ¢n thiá»‡n, Æ°u tiÃªn ngáº¯n gá»n vÃ  sÃ¡t cÃ¢u há»i."
)


def _sigmoid(value: float | None) -> float:
    if value is None:
        return 0.0
    try:
        v = float(value)
    except (TypeError, ValueError):
        return 0.0
    if v >= 50:
        return 1.0
    if v <= -50:
        return 0.0
    return 1.0 / (1.0 + math.exp(-v))


def _ensure_init():
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        raise RuntimeError("GEMINI_API_KEY chÆ°a Ä‘Æ°á»£c cáº¥u hÃ¬nh.")
    genai.configure(api_key=api_key)


def _build_context(passages: List[Chunk]) -> str:
    parts = []
    for idx, p in enumerate(passages, start=1):
        relevance = 0.0
        if isinstance(getattr(p, "meta", None), dict):
            relevance = float(p.meta.get("relevance", 0.0) or 0.0)
        elif getattr(p, "score", None) is not None:
            relevance = _sigmoid(p.score)
        header = f"[{idx}] {p.doc_name}:{p.page} (Ä‘á»™ phÃ¹ há»£p â‰ˆ {relevance:.2f})"
        text = p.text.replace("\n", " ").strip()
        if len(text) > 1200:
            text = text[:1200] + "â€¦"
        parts.append(f"{header}\n{text}")
    return "\n\n".join(parts)


def generate(query: str, passages: List[Chunk]) -> Tuple[str, float]:
    _ensure_init()
    context = _build_context(passages)

    # Prompt tá»‘i Æ°u cho format Ä‘áº¹p vÃ  cÃ¢u tráº£ lá»i Ä‘áº§y Ä‘á»§
    prompt = f"""{SYSTEM_PROMPT}

=== THÃ”NG TIN Tá»ª TÃ€I LIá»†U ===
{context}

=== CÃ‚U Há»I ===
{query}

=== YÃŠU Cáº¦U ===
HÃ£y tráº£ lá»i THEO ÄÃšNG Cáº¤U TRÃšC trÃªn vá»›i:
- Xuá»‘ng dÃ²ng rÃµ rÃ ng giá»¯a cÃ¡c pháº§n
- Sá»­ dá»¥ng **bold** cho tiÃªu Ä‘á» 
- Bullet points cho danh sÃ¡ch
- Tráº£ lá»i Äáº¦Y Äá»¦, khÃ´ng Ä‘Æ°á»£c cáº¯t giá»¯a chá»«ng
- TRÃCH DáºªN: Sá»­ dá»¥ng tÃªn file CHÃNH XÃC tá»« context á»Ÿ trÃªn, vÃ­ dá»¥ [tb741.pdf:2] chá»© KHÃ”NG PHáº¢I [doc:1]"""

    model = genai.GenerativeModel(
        LLM_MODEL,
        generation_config={
            "temperature": TEMP,
            "max_output_tokens": MAX_OUT,
            "candidate_count": 1,
        },
    )
    resp = model.generate_content(prompt)

    feedback = getattr(resp, "prompt_feedback", None)
    if feedback and getattr(feedback, "block_reason", None):
        raise RuntimeError(f"YÃªu cáº§u bá»‹ tá»« chá»‘i: {feedback.block_reason}")

    answer = ""
    if hasattr(resp, "text") and resp.text:
        answer = resp.text.strip()
    elif getattr(resp, "candidates", None):
        for candidate in resp.candidates:
            parts = getattr(getattr(candidate, "content", None), "parts", [])
            texts = [p.text for p in parts if getattr(p, "text", None)]
            if texts:
                answer = "\n".join(texts).strip()
                if answer:
                    break
    if not answer:
        raise RuntimeError("KhÃ´ng nháº­n Ä‘Æ°á»£c pháº£n há»“i tá»« mÃ´ hÃ¬nh.")

    if passages:
        scores = [_sigmoid(p.score) for p in passages]
        conf = sum(scores) / len(scores)
    else:
        conf = 0.0
    return answer, float(conf)
